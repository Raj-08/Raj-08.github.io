---
layout: post
title:  "Deep inside Deep Dream+Code in Tensorflow"
date:   2015-10-26 16:51:11
categories: blog
---

Visualization or Imagination is a very high form of intelligence possesed by us human biengs. To be able to see things that don't exist requires a very high level of conciousness. These highly intelligent activities can be found in our daily activities:

1.When we want to paint a scenery that we imagine
2.When we interpret cloud shapes as different objects
3.When we dream

All of these activities require our brain to do something different rather than just interpret the visual information it is recieving. When we see a cloud for example we may say that it looks like a Dog or like an Elephant. Clearly they aren't actual Dogs or Elephants flying in the skies but they have some similarity. Even though this similarity is minimal,our Brain somehow manage to connect the missing dots to form a complete picture.

So when we see a cloud and we interpret it to something , our brain essentially kept adding information to the visual scene(imagination) that we can't see. So we need to see what is happening in our brain exactly. While this is an abstruse concept we can use Convolutional Neural Networks to know more about what is happening between layers of our Brain. 


<!-- {% include image name="blue-clouds.jpeg" caption="Before Dreaming!" %}
 -->
 {% include image name="blue-clouds.jpeg" caption="Before Dreaming!" %}


The layers in CNN store informations related to the things it is trained to recognize.Infact we know that the starting layers of CNN store very minimal details like strokes , lines, shapes , edges and contours. And the final layers of the CNN use those details provided by the initial layers to form a more defined image. Hence these layers essentially stores the visual information.

So lets give a trained CNN an image. It is pretty much analogous to the case when we are looking at the clouds. Then we pick a layer from the CNN and enhance what it has detected so far. By enhancing we mean that we want to see what its activations are for an entire layer , by backproping the gradient of that activation back to the input image.Gradient is a measure how things are changing or in our case we mean that gradient is a way of visualization or imagination.

So when we were doing the task of recognition using a CNN which is a discriminative process and we essentially wanted what category does a particular image belong to. It involved gradient descent and we wanted to minimize the cost function .But here we perform gradient ascent and maximize the layer's activation. So essentially we will be following the direction of the gradient(ascent) and will be maximizing the selected layer or neuron's activation by changing our input image that is by adding the gradient back to the image.

Here we are using a pretrained model by Google called the Inception V5 . This is implimented using Tensorflow.

Lets dig in :)

Lets import the inception model :

{% highlight html %}
from libs import inception
net = inception.get_inception_model()
{% endhighlight %}

Now we will get the inception graph:

{% highlight html %}

device = '/cpu:0'

g = tf.Graph()

with tf.Session(graph=g) as sess, g.device(device):
    
    # Now load the graph_def, which defines operations and their values into `g`
    tf.import_graph_def(net['graph_def'], name='net')
{% endhighlight %}

Let's see all the operations that exist in this graph:

{% highlight html %}
names = [op.name for op in g.get_operations()]
print(names[0])
{% endhighlight %}

Now we need to select the layers ,

{% highlight html %}
names = [op.name for op in g.get_operations()]
print(names[0])
{% endhighlight %}

And select the first layer to which the gradients will be added:

{% highlight html %}
x = g.get_tensor_by_name('net/images:0');
{% endhighlight %}

As we know we want to calculate the gradient of layers with respect to the input layer and add the gradients back to the input image. For this purpose we use Tensorflow's tf.gradient to caluclate the differential between the two. This is effectively telling us which pixels contribute to the predicted layer, class, or given neuron with the layer.Hence we define a plot_gradient function that takes the input image , input layer and the layer we selected.

{% highlight html %}
def plot_gradient(img, x, feature, g, device='/cpu:0'):
    with tf.Session(graph=g) as sess, g.device(device):
        saliency = tf.gradients(tf.reduce_mean(feature), x)
        this_res = sess.run(saliency[0], feed_dict={x: img})
        grad = this_res[0] / np.max(np.abs(this_res))
        return grad
{% endhighlight %}

Now its time to define the Dream function that will do all the dreamy work. Our Gradients represent the direction we should move our input in order to meet our objective stored in "gradient"
    
Lets look at what our image looks like after dreaming :


{% include image name="download(1).png" caption="After Dreaming!" %}
















{% highlight html %}
def dream(img, gradient, step, net, x, n_iterations=50, plot_step=10):
    img_copy = img.copy()

    fig, axs = plt.subplots(1, n_iterations // plot_step, figsize=(20, 10))

    with tf.Session(graph=g) as sess, g.device(device):
        for it_i in range(n_iterations):
            this_res = sess.run(gradient[0], feed_dict={x: img_copy})[0]

            # Let's normalize it by the maximum activation
            this_res /= (np.max(np.abs(this_res) + 1e-8))
            
            # Adding the gradient back to the input image
            img_copy += this_res * step

            # Plot the image
            if (it_i + 1) % plot_step == 0:
                m = net['deprocess'](img_copy[0])
                axs[it_i // plot_step].imshow(m)
{% endhighlight %}





